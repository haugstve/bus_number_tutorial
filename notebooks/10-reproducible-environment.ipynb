{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Reproducible Environments\n",
    "(Continued from `README.md`)\n",
    "\n",
    "## Overview\n",
    "\n",
    "* Requirements: The Bare Minimum \n",
    "\n",
    "* Using a Data Science Template: `cookiecutter`\n",
    "\n",
    "* Virtual Environments: `conda` and environment files\n",
    "* Revision Control: git and a git workflow\n",
    "   * Installing, Enabling, and using nbdime\n",
    "* The Data Science DAG\n",
    "   * make, Makefiles and data flow\n",
    "* Python Modules\n",
    "   * Creating an editable module\n",
    "* Testing: doctest, pytest, hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start out by checking that all the requirements are met from the previous exercises (started in `README.md`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Install the requirements\n",
    "\n",
    "* Anaconda\n",
    "* Cookiecutter\n",
    "* make\n",
    "* git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda 4.6.14\r\n"
     ]
    }
   ],
   "source": [
    "!conda --version   # or `$CONDA_EXE --version` in some environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNU Make 3.81\r\n",
      "Copyright (C) 2006  Free Software Foundation, Inc.\r\n",
      "This is free software; see the source for copying conditions.\r\n",
      "There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A\r\n",
      "PARTICULAR PURPOSE.\r\n",
      "\r\n",
      "This program built for i386-apple-darwin11.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!make --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git version 2.20.1 (Apple Git-117)\r\n"
     ]
    }
   ],
   "source": [
    "!git --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Start your cookiecutter-based project\n",
    "\n",
    "Create a project called `Bus Number Tutorial`:\n",
    "\n",
    "    Use conda as your virtualenv manager\n",
    "    Use python 3.6 or greater\n",
    "\n",
    "When complete, you should have a fully populated project directory, complete with customized README.md.\n",
    "\n",
    "We will be working in this project from now on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2b:\n",
    "\n",
    "Explore the `README.md` from your new `bus_number_tutorial` repo\n",
    "\n",
    "(Hint: You can use the `%load` magic, or `!cat` to look at it in your notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %load '../README.md'\n",
    "Bus Number Tutorial\n",
    "==============================\n",
    "\n",
    "Increase my bus number\n",
    "\n",
    "GETTING STARTED\n",
    "---------------\n",
    "\n",
    "* Create and switch to the  virtual environment:\n",
    "```\n",
    "cd bus_number_tutorial\n",
    "make create_environment\n",
    "conda activate bus_number_tutorial\n",
    "make requirements\n",
    "```\n",
    "* Explore the notebooks in the `notebooks` directory\n",
    "\n",
    "Project Organization\n",
    "------------\n",
    "* `LICENSE`\n",
    "* `Makefile`\n",
    "    * top-level makefile. Type `make` for a list of valid commands\n",
    "* `README.md`\n",
    "    * this file\n",
    "* `data`\n",
    "    * Data directory. often symlinked to a filesystem with lots of space\n",
    "    * `data/raw`\n",
    "        * Raw (immutable) hash-verified downloads\n",
    "    * `data/interim`\n",
    "        * Extracted and interim data representations\n",
    "    * `data/processed`\n",
    "        * The final, canonical data sets for modeling.\n",
    "* `docs`\n",
    "    * A default Sphinx project; see sphinx-doc.org for details\n",
    "* `models`\n",
    "    * Trained and serialized models, model predictions, or model summaries\n",
    "    * `models/trained`\n",
    "        * Trained models\n",
    "    * `models/output`\n",
    "        * predictions and transformations from the trained models\n",
    "* `notebooks`\n",
    "    *  Jupyter notebooks. Naming convention is a number (for ordering),\n",
    "    the creator's initials, and a short `-` delimited description,\n",
    "    e.g. `1.0-jqp-initial-data-exploration`.\n",
    "* `references`\n",
    "    * Data dictionaries, manuals, and all other explanatory materials.\n",
    "* `reports`\n",
    "    * Generated analysis as HTML, PDF, LaTeX, etc.\n",
    "    * `reports/figures`\n",
    "        * Generated graphics and figures to be used in reporting\n",
    "    * `reports/tables`\n",
    "        * Generated data tables to be used in reporting\n",
    "    * `reports/summary`\n",
    "        * Generated summary information to be used in reporting\n",
    "* `requirements.txt`\n",
    "    * (if using pip+virtualenv) The requirements file for reproducing the\n",
    "    analysis environment, e.g. generated with `pip freeze > requirements.txt`\n",
    "* `environment.yml`\n",
    "    * (if using conda) The YAML file for reproducing the analysis environment\n",
    "* `setup.py`\n",
    "    * Turns contents of `src` into a\n",
    "    pip-installable python module  (`pip install -e .`) so it can be\n",
    "    imported in python code\n",
    "* `src`\n",
    "    * Source code for use in this project.\n",
    "    * `src/__init__.py`\n",
    "        * Makes src a Python module\n",
    "    * `src/data`\n",
    "        * Scripts to fetch or generate data. In particular:\n",
    "        * `src/data/make_dataset.py`\n",
    "            * Run with `python -m src.data.make_dataset fetch`\n",
    "            or  `python -m src.data.make_dataset process`\n",
    "    * `src/analysis`\n",
    "        * Scripts to turn datasets into output products\n",
    "    * `src/models`\n",
    "        * Scripts to train models and then use trained models to make predictions.\n",
    "        e.g. `predict_model.py`, `train_model.py`\n",
    "* `tox.ini`\n",
    "    * tox file with settings for running tox; see tox.testrun.org\n",
    "\n",
    "\n",
    "--------\n",
    "\n",
    "<p><small>This project was built using <a target=\"_blank\" href=\"https://github.com/hackalog/cookiecutter-easydata\">cookiecutter-easydata</a>, an experimental fork of [cookiecutter-data-science](https://github.com/drivendata/cookiecutter-data-science) aimed at making your data science workflow reproducible.</small></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Set up your virtual environment and install all dependencies\n",
    "\n",
    "Create and activate your `bus_number_tutorial` conda environment using the above make commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `active environment` should be `bus_number_tutorial`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "     active environment : bus_number_tutorial\r\n",
      "    active env location : /anaconda3/envs/bus_number_tutorial\r\n",
      "            shell level : 2\r\n",
      "       user config file : /Users/danielhaugstvedt/.condarc\r\n",
      " populated config files : /Users/danielhaugstvedt/.condarc\r\n",
      "          conda version : 4.6.14\r\n",
      "    conda-build version : 3.15.1\r\n",
      "         python version : 3.6.8.final.0\r\n",
      "       base environment : /anaconda3  (writable)\r\n",
      "           channel URLs : https://conda.anaconda.org/conda-forge/osx-64\r\n",
      "                          https://conda.anaconda.org/conda-forge/noarch\r\n",
      "                          https://repo.anaconda.com/pkgs/main/osx-64\r\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\r\n",
      "                          https://repo.anaconda.com/pkgs/free/osx-64\r\n",
      "                          https://repo.anaconda.com/pkgs/free/noarch\r\n",
      "                          https://repo.anaconda.com/pkgs/r/osx-64\r\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\r\n",
      "          package cache : /anaconda3/pkgs\r\n",
      "                          /Users/danielhaugstvedt/.conda/pkgs\r\n",
      "       envs directories : /anaconda3/envs\r\n",
      "                          /Users/danielhaugstvedt/.conda/envs\r\n",
      "               platform : osx-64\r\n",
      "             user-agent : conda/4.6.14 requests/2.19.1 CPython/3.6.8 Darwin/18.6.0 OSX/10.14.5\r\n",
      "                UID:GID : 501:20\r\n",
      "             netrc file : None\r\n",
      "           offline mode : False\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you are using **JupyterHub**, the bash magics `!` and `%%bash` will not work as expected, that is, they will drop you into your root JupyterHub environment, as opposed to the conda kernel that you a running this notebook in, and you will not see `bus_number_tutorial`. To get around this, you will need to run the bash commands in this notebook from a terminal instance with your `bus_number_tutorial` conda environment activated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If done correctly, you should also be able to import from `src`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if importing src doesn't work, try `make requirements`\n",
    "import src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Pick up this tutorial in your new repo\n",
    "\n",
    "* Run jupyter notebook and open `notebooks/10-reproducible-environment.ipynb`\n",
    "\n",
    "If you're currently running this notebook and the checks from the previous exercises worked, then you're in business!\n",
    "\n",
    "Keep going from here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revision Control: `git`\n",
    "\n",
    "How do we keep track of our changes? We use **git**.\n",
    "\n",
    "Before we do anything interesting, let's initialize a git repository (repo) here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Initialize a git repo for `bus_number_tutorial`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "git init\n",
    "git add .\n",
    "git commit -m \"Initial Import\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is ahead of 'origin/master' by 2 commits.\r\n",
      "  (use \"git push\" to publish your local commits)\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   10-reproducible-environment.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../src/utils.py\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get back to using git again soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Add a dependency\n",
    "Modify the environment file so that `make requirements` installs some additional packages\n",
    "* install `joblib` using conda\n",
    "* install `nbdime` using pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that you now have joblib  and nbdime installed\n",
    "# Don't forget that you need to run `make requirements` once you've change the `environment.yml` file\n",
    "import joblib\n",
    "import nbdime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: Basic git interactions\n",
    "\n",
    "Check the changes to your `environment.yml` file into your git repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what has changed with git:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is ahead of 'origin/master' by 2 commits.\r\n",
      "  (use \"git push\" to publish your local commits)\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   10-reproducible-environment.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../src/utils.py\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git diff -u ../environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add or reject your changes incrementally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git add -p\n",
    "#!git reset -p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commit the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git commit -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is ahead of 'origin/master' by 2 commits.\r\n",
      "  (use \"git push\" to publish your local commits)\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   10-reproducible-environment.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../src/utils.py\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "# You should have no differences in your branch now\n",
    "# Except for those that you've made by running notebooks\n",
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Science DAG\n",
    "DAG = Directed Acyclic Graph. \n",
    "\n",
    "That means the process eventually stops. (This is a good thing!) \n",
    "\n",
    "It also means we can use a super old, but incredibly handy tool to implement this workflow: `make`.\n",
    "\n",
    "### Make, Makefiles, and the Data Flow\n",
    "\n",
    "\n",
    "We use a `Makefile` to organize and invoke the various steps in our Data Science pipeline.\n",
    "You have already used this file when you created your virtual environment in the first place:\n",
    "```\n",
    "make create_environment\n",
    "```\n",
    "Here are the steps we will be working through in this tutorial:\n",
    "<img src=\"references/cheat_sheet.png\" alt=\"Reproducible Data Science Workflow\" width=\"400\"/>\n",
    "\n",
    "A [PDF version of the cheat sheet](references/cheat_sheet.pdf) is also available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### What's my make target doing?\n",
    "If you are ever curious what commands a `make` command will invoke (including any invoked dependencies), use `make -n`, which lists the commands without executing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danielhaugstvedt/Developer/bus_number_tutorial/notebooks\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 test_environment.py\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd .. && make -n requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a cute **self-documenting makefiles trick** (borrowed from `cookiecutter-datascience`) to make it easy to document the various targets that you add. This documentation is produced when you type a plain `make`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get started:\n",
      "  >>> \u001b[1mmake create_environment\u001b[m\n",
      "  >>> \u001b[1mconda activate bus_number_tutorial\u001b[m\n",
      "\n",
      "\u001b[1mProject Variables:\u001b[m\n",
      "PROJECT_NAME = bus_number_tutorial\n",
      "\n",
      "\u001b[1mAvailable rules:\u001b[m\n",
      "\u001b[36manalysis           \u001b[m Convert predictions / transforms / experiments into output \n",
      "                    data \n",
      "\u001b[36mclean              \u001b[m Delete all compiled Python files \n",
      "\u001b[36mclean_interim      \u001b[m Delete all interim (DataSource) files \n",
      "\u001b[36mclean_models       \u001b[m Delete all trained models \n",
      "\u001b[36mclean_predictions  \u001b[m Delete all predictions \n",
      "\u001b[36mclean_processed    \u001b[m Delete all processed datasets \n",
      "\u001b[36mclean_raw          \u001b[m Delete the raw downloads directory \n",
      "\u001b[36mcreate_environment \u001b[m Set up virtual environment for this project \n",
      "\u001b[36mdata               \u001b[m convert raw datasets into fully processed datasets \n",
      "\u001b[36mdelete_environment \u001b[m Delete the virtual environment for this project \n",
      "\u001b[36mlint               \u001b[m Lint using flake8 \n",
      "\u001b[36mpredict            \u001b[m predict / transform / run experiments \n",
      "\u001b[36mrequirements       \u001b[m Install or update Python Dependencies \n",
      "\u001b[36msources            \u001b[m Fetch, Unpack, and Process raw DataSources \n",
      "\u001b[36msync_data_from_s3  \u001b[m Download Data from S3 \n",
      "\u001b[36msync_data_to_s3    \u001b[m Upload Data to S3 \n",
      "\u001b[36mtest               \u001b[m Run all Unit Tests \n",
      "\u001b[36mtest_environment   \u001b[m Test python environment is set-up correctly \n",
      "\u001b[36mtrain              \u001b[m train / fit / build models \n",
      "\u001b[36mtransform_data     \u001b[m Apply Transformations to produce fully processed Datsets \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd .. && make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under the Hood: The Format of a Makefile\n",
    "\n",
    "```\n",
    "## Comment to appear in the auto-generated documentation\n",
    "thing_to_build: space separated list of dependencies\n",
    "\tcommand_to_run            # there is a tab before this command.\n",
    "\tanother_command_to_run    # every line gets run in a *new shell*\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Makefile.test\n"
     ]
    }
   ],
   "source": [
    "%%file Makefile.test\n",
    "\n",
    "data: raw\n",
    "\t@echo \"Build Datasets\"\n",
    "train_test_split:\n",
    "\t@echo \"do train/test split\"\n",
    "train: data transform_data train_test_split\n",
    "\t@echo \"Train Models\"\n",
    "transform_data:\n",
    "\t@echo \"do a data transformation\"\n",
    "raw:\n",
    "\t@echo \"Fetch raw data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetch raw data\r\n",
      "Build Datasets\r\n"
     ]
    }
   ],
   "source": [
    "# Note: you can run a specific Makefile with with -f option\n",
    "!make -f Makefile.test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you see: ```*** missing separator.  Stop.``` it's because you have used spaces instead of **tabs** before your commands. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: What does this `Makefile.test` print when you run `make train`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9: What happens when you add a cycle to a Makefile\n",
    "Set up a makefile with a cyclic dependency and run it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It prints:\n",
    "\n",
    "`make: Circular raw <- data dependency dropped.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Makefile like this is an easy way to set up a process flow expressed as a Directed Acyclic Graph (DAG).\n",
    "\n",
    "**Note**: We have only scratched the surface here. The are lots of interesting tricks you can do with make.\n",
    "* http://zmjones.com/make/\n",
    "* http://blog.byronjsmith.com/makefile-shortcuts.html\n",
    "* https://www.gnu.org/software/make/manual/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Revision Control: git workflows\n",
    "\n",
    "Git isn't really a collaboration tool. It's more a tool for implementing collaboration workflows.\n",
    "\n",
    "What do we mean by workflow? A process built on top of git that incorporates **pull requests** and **branches**. Typically, this is provided by sites like: GitHub, GitLab, BitBucket.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10: \n",
    "\n",
    "Create a GitHub/GitLab/BitBucket repo and sync your repo to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\thttps://github.com/haugstve/bus_number_tutorial.git (fetch)\r\n",
      "origin\thttps://github.com/haugstve/bus_number_tutorial.git (push)\r\n"
     ]
    }
   ],
   "source": [
    "# your remote repo should now show up\n",
    "!git remote -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example (using SSL):\n",
    "\n",
    "    origin\tgit@github.com:${GITHUB_USERNAME}/bus_number_tutorial.git (fetch)\n",
    "   \n",
    "    origin\tgit@github.com:${GITHUB_USERNAME}/bus_number_tutorial.git (push)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitHub workflow cheatsheet\n",
    "See https://github.com/hackalog/bus_number/wiki/Github-Workflow-Cheat-Sheet\n",
    "\n",
    "## Life Rules for using `git`\n",
    "\n",
    "* Always work on a branch: `git checkout -b my_branch_name`. Delete branches once they are merged.\n",
    "* **Never** push to master. Always **work on a branch** and do a pull request.\n",
    "* Seriously, don't do work on master if you are collaborating with **anyone**.\n",
    "* If you pushed it anywhere, or shared it with anyone, don't `git rebase`. In fact, if you're reading this, don't `git rebase`. Save that for when you are comfortable solving git merge nightmares on your own.\n",
    "\n",
    "Here are some common tasks in git/github\n",
    "\n",
    "### Starting the day. Where was I? What was I doing?\n",
    "```\n",
    "git branch         # What branch am I currently on? e.g. {my_branch}\n",
    "git status         # anything I forgot to commit? If so...\n",
    "git commit ...     # Commit work in progress\n",
    "```\n",
    "\n",
    "### Didn't I do some work at home last night?\n",
    "```\n",
    "git checkout master       # leave whatever branch I was on\n",
    "git fetch origin --prune  # Check for something new\n",
    "git merge origin/master   # If updates available, update!\n",
    "git branch --merged master # check for any merged branches that can be safely deleted\n",
    "git branch -d {name_of_merged_branch} # delete any fully merged branches\n",
    "```\n",
    "\n",
    "### Anything fun happening upstream?\n",
    "\n",
    "```\n",
    "git checkout master\n",
    "git fetch upstream --prune  # grab latest changes from upstream repo\n",
    "git merge upstream/master   # merge them into local copy of my form\n",
    "git push origin master      # push latest upstream changes to my forked repo\n",
    "git branch --merged master # check for any merged branches that can be safely deleted\n",
    "git branch -d {name_of_merged_branch} # delete any fully merged branches\n",
    "```\n",
    "\n",
    "Now that `master` is up to date, you should merge whatever happened in `master` into your development branch:\n",
    "```\n",
    "git checkout {my_branch}\n",
    "git merge master               # merges master->{my_branch}\n",
    "git push origin {my_branch}    # Let Github know about the merge\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some useful references if `gitflow` isn't second nature to you yet\n",
    "* Introduction to GitHub tutorial: https://lab.github.com/githubtraining/introduction-to-github\n",
    "* Git Handbook: https://guides.github.com/introduction/git-handbook/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11:\n",
    "* Create a branch called `add_sklearn`\n",
    "* Add a scikit-learn dependency\n",
    "* Check in these changes using git to your local repo\n",
    "* Push the new branch to GitHub\n",
    "* Create a pull request to merge this branch into master\n",
    "* Merge your PR (delete the branch afterwards)\n",
    "* Sync your local repo with GitHub, including deleting the merged branches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Modules\n",
    "By default, we keep our source code in a module called `src`. (this can be overridden in the cookieccutter)\n",
    "\n",
    "This is enabled via one line in `environment.yml`:\n",
    "```\n",
    "- pip:\n",
    "  - -e .\n",
    "```\n",
    "\n",
    "This creates an **editable module**, and looks in the current directory for a file called `setup.py` to indicate the module name and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "usage: ipykernel_launcher.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n   or: ipykernel_launcher.py --help [cmd1 cmd2 ...]\n   or: ipykernel_launcher.py --help-commands\n   or: ipykernel_launcher.py cmd --help\n\nerror: option -f not recognized",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m usage: ipykernel_launcher.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n   or: ipykernel_launcher.py --help [cmd1 cmd2 ...]\n   or: ipykernel_launcher.py --help-commands\n   or: ipykernel_launcher.py cmd --help\n\nerror: option -f not recognized\n"
     ]
    }
   ],
   "source": [
    "# %load ../setup.py\n",
    "from setuptools import find_packages, setup\n",
    "\n",
    "setup(\n",
    "    name='src',\n",
    "    packages=find_packages(),\n",
    "    version='0.0.1',\n",
    "    description='Increase my bus number',\n",
    "    author='haugstve',\n",
    "    license='MIT',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lets you easily use your code in notebooks and other scripts, and avoids any `sys.path.append` silliness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASIDE: Semantic Versioning\n",
    "\n",
    "Semantic versioning (or *semver*), refers to the convention of versioning with a triple:\n",
    "\n",
    "    MAJOR.MINOR.PATCH\n",
    "\n",
    "With the following convention: when releasing new versions, increment the:\n",
    "\n",
    "*    MAJOR version when you make **incompatible API changes**,\n",
    "*    MINOR version when you **add functionality** in a backwards-compatible manner, and\n",
    "*    PATCH version when you make backwards-compatible **bug fixes**.\n",
    "\n",
    "If you have no other plan, this is a great convention to follow.\n",
    "\n",
    "For an obscene amount of detail on this concept, see https://semver.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11:\n",
    "* add your favorite utility function to `src/utils`\n",
    "* increment the version number of the editable package (do this in `setup.py`)\n",
    "* run `make requirements` (required if you added dependencies for your utility function)\n",
    "* import your utility function and run it from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import dplyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_json('test.json',['a','b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'col1': [1, 2, 3, 4], \n",
    "                    'col2': [1, 2, 1, 2],\n",
    "                    'col3': ['a', 'b', 'a', 'b']})\n",
    "df.filter('col2 == 2').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>sepal_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.483871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1.388889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species  sepal_ratio\n",
       "0           5.1          3.5           1.4          0.2  setosa     1.457143\n",
       "1           4.9          3.0           1.4          0.2  setosa     1.633333\n",
       "2           4.7          3.2           1.3          0.2  setosa     1.468750\n",
       "3           4.6          3.1           1.5          0.2  setosa     1.483871\n",
       "4           5.0          3.6           1.4          0.2  setosa     1.388889"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(iris.mutate(sepal_ratio = iris.sepal_length/iris.sepal_width)\n",
    "     .head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width\n",
       "0           5.1          3.5\n",
       "1           4.9          3.0\n",
       "2           4.7          3.2\n",
       "3           4.6          3.1\n",
       "4           5.0          3.6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(iris.select('sepal_length','sepal_width')\n",
    "     .head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(iris.filter('sepal_length > 4')\n",
    "     .head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width species\n",
       "13           4.3          3.0           1.1          0.1  setosa\n",
       "42           4.4          3.2           1.3          0.2  setosa\n",
       "38           4.4          3.0           1.3          0.2  setosa\n",
       "8            4.4          2.9           1.4          0.2  setosa\n",
       "41           4.5          2.3           1.3          0.3  setosa"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(iris.arrange(by = 'sepal_length')\n",
    "     .head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A handy magic that allows us to edit modules and have them stay up to date in the notebook. In this case, src.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing: doctest, pytest, coverage\n",
    "\n",
    "\n",
    "Python has built in testing frameworks via:\n",
    "* doctests:https://docs.python.org/3/library/doctest.html#module-doctest\n",
    "* unittest: https://docs.python.org/3/library/unittest.html\n",
    "\n",
    "Additionally, you'll want to make regular use of:\n",
    "* pytest: https://docs.pytest.org/en/latest/\n",
    "* pytest-cov: https://pypi.org/project/pytest-cov/\n",
    "* hypothesis: https://hypothesis.readthedocs.io/en/latest\n",
    "\n",
    "Cookiecutter (vanilla flavoured) comes witha setup for the `tox` testing framework built in.\n",
    "* https://tox.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12:\n",
    "\n",
    "Add a `make test` target to your makefile that:\n",
    "* runs doctests\n",
    "* runs pytest unit tests\n",
    "* (extra credit) Displays test coverage results\n",
    "    \n",
    "When you run `make test`, you will find tests that will fail in `src/test_example.py`. Fix them in the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd src && pytest --doctest-modules --cov\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.7.3, pytest-4.6.3, py-1.8.0, pluggy-0.12.0\n",
      "rootdir: /Users/danielhaugstvedt/Developer/bus_number_tutorial\n",
      "plugins: nbval-0.9.1, cov-2.7.1\n",
      "collected 8 items                                                              \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "dplyr.py \u001b[32m.\u001b[0m\u001b[36m                                                               [ 12%]\u001b[0m\n",
      "test_example.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                                       [ 37%]\u001b[0m\n",
      "data/fetch.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                                       [ 87%]\u001b[0m\n",
      "data/utils.py \u001b[32m.\u001b[0m\u001b[36m                                                          [100%]\u001b[0mCoverage.py warning: Couldn't read data from '/Users/danielhaugstvedt/Developer/bus_number_tutorial/src/.coverage.daniels-mbp.oslo.no.ibm.com.77752.109619': CoverageException: Doesn't seem to be a coverage.py data file\n",
      "Coverage.py warning: Couldn't read data from '/Users/danielhaugstvedt/Developer/bus_number_tutorial/src/.coverage.daniels-mbp.oslo.no.ibm.com.79868.474315': CoverageException: Doesn't seem to be a coverage.py data file\n",
      "Coverage.py warning: Couldn't read data from '/Users/danielhaugstvedt/Developer/bus_number_tutorial/src/.coverage.daniels-mbp.oslo.no.ibm.com.77761.954994': CoverageException: Doesn't seem to be a coverage.py data file\n",
      "\n",
      "\n",
      "---------- coverage: platform darwin, python 3.7.3-final-0 -----------\n",
      "Name                         Stmts   Miss  Cover\n",
      "------------------------------------------------\n",
      "__init__.py                      0      0   100%\n",
      "analysis/__init__.py             0      0   100%\n",
      "analysis/analysis.py           105     86    18%\n",
      "analysis/run_analysis.py        23      9    61%\n",
      "data/__init__.py                 4      0   100%\n",
      "data/apply_transforms.py        27     12    56%\n",
      "data/datasets.py               322    272    16%\n",
      "data/fetch.py                  152    117    23%\n",
      "data/localdata.py                1      0   100%\n",
      "data/make_dataset.py            15      4    73%\n",
      "data/transform_data.py          88     72    18%\n",
      "data/transformers.py            42     29    31%\n",
      "data/utils.py                   85     61    28%\n",
      "dplyr.py                        14      2    86%\n",
      "features/__init__.py             0      0   100%\n",
      "features/build_features.py       0      0   100%\n",
      "logging.py                       7      0   100%\n",
      "models/__init__.py               3      0   100%\n",
      "models/algorithms.py             5      4    20%\n",
      "models/model_list.py            74     60    19%\n",
      "models/predict.py              100     80    20%\n",
      "models/predict_model.py         22      9    59%\n",
      "models/train.py                 54     39    28%\n",
      "models/train_models.py          25     11    56%\n",
      "paths.py                        17      0   100%\n",
      "test_example.py                  8      0   100%\n",
      "utils.py                        49     37    24%\n",
      "visualization/__init__.py        0      0   100%\n",
      "visualization/visualize.py       0      0   100%\n",
      "workflow.py                      8      0   100%\n",
      "------------------------------------------------\n",
      "TOTAL                         1250    904    28%\n",
      "\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 8 passed in 1.34 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd .. && make test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** `make test` is normally functionality built into `cookiecutter-easydata`. We're building it from scratch here for the sake of practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13:\n",
    "Fix the failing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd src && pytest --doctest-modules --cov\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.7.3, pytest-4.6.3, py-1.8.0, pluggy-0.12.0\n",
      "rootdir: /Users/danielhaugstvedt/Developer/bus_number_tutorial\n",
      "plugins: nbval-0.9.1, cov-2.7.1\n",
      "collected 8 items                                                              \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "dplyr.py \u001b[32m.\u001b[0m\u001b[36m                                                               [ 12%]\u001b[0m\n",
      "test_example.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                                       [ 37%]\u001b[0m\n",
      "data/fetch.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                                       [ 87%]\u001b[0m\n",
      "data/utils.py \u001b[32m.\u001b[0m\u001b[36m                                                          [100%]\u001b[0mCoverage.py warning: Couldn't read data from '/Users/danielhaugstvedt/Developer/bus_number_tutorial/src/.coverage.daniels-mbp.oslo.no.ibm.com.77752.109619': CoverageException: Doesn't seem to be a coverage.py data file\n",
      "Coverage.py warning: Couldn't read data from '/Users/danielhaugstvedt/Developer/bus_number_tutorial/src/.coverage.daniels-mbp.oslo.no.ibm.com.79868.474315': CoverageException: Doesn't seem to be a coverage.py data file\n",
      "Coverage.py warning: Couldn't read data from '/Users/danielhaugstvedt/Developer/bus_number_tutorial/src/.coverage.daniels-mbp.oslo.no.ibm.com.77761.954994': CoverageException: Doesn't seem to be a coverage.py data file\n",
      "\n",
      "\n",
      "---------- coverage: platform darwin, python 3.7.3-final-0 -----------\n",
      "Name                         Stmts   Miss  Cover\n",
      "------------------------------------------------\n",
      "__init__.py                      0      0   100%\n",
      "analysis/__init__.py             0      0   100%\n",
      "analysis/analysis.py           105     86    18%\n",
      "analysis/run_analysis.py        23      9    61%\n",
      "data/__init__.py                 4      0   100%\n",
      "data/apply_transforms.py        27     12    56%\n",
      "data/datasets.py               322    272    16%\n",
      "data/fetch.py                  152    117    23%\n",
      "data/localdata.py                1      0   100%\n",
      "data/make_dataset.py            15      4    73%\n",
      "data/transform_data.py          88     72    18%\n",
      "data/transformers.py            42     29    31%\n",
      "data/utils.py                   85     61    28%\n",
      "dplyr.py                        14      2    86%\n",
      "features/__init__.py             0      0   100%\n",
      "features/build_features.py       0      0   100%\n",
      "logging.py                       7      0   100%\n",
      "models/__init__.py               3      0   100%\n",
      "models/algorithms.py             5      4    20%\n",
      "models/model_list.py            74     60    19%\n",
      "models/predict.py              100     80    20%\n",
      "models/predict_model.py         22      9    59%\n",
      "models/train.py                 54     39    28%\n",
      "models/train_models.py          25     11    56%\n",
      "paths.py                        17      0   100%\n",
      "test_example.py                  8      0   100%\n",
      "utils.py                        49     37    24%\n",
      "visualization/__init__.py        0      0   100%\n",
      "visualization/visualize.py       0      0   100%\n",
      "workflow.py                      8      0   100%\n",
      "------------------------------------------------\n",
      "TOTAL                         1250    904    28%\n",
      "\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 8 passed in 1.55 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Should pass all tests now!\n",
    "!cd .. && make test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14:\n",
    "* Check in all your changes to git\n",
    "* Merge them into your master branch via a PR in GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is ahead of 'origin/master' by 6 commits.\r\n",
      "  (use \"git push\" to publish your local commits)\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   10-reproducible-environment.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../src/test_example.py\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
